{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import uproot\n",
    "import awkward as ak\n",
    "import vector\n",
    "import numba as nb\n",
    "import os\n",
    "import fnmatch\n",
    "from dnn_tau import Dnn_tau\n",
    "from kinematic import *\n",
    "from utils import isolate_int, normalize\n",
    "import pandas as pd\n",
    "from numbers import Number\n",
    "from utils import normalize, split_dataset, bucketize\n",
    "from data_extractor import Data_extractor_v1\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/data/hnl/prompt_tau/anatuple/nanoV10/TEST6/ttm_DeepTau2p5/\"\n",
    "extractor = Data_extractor_v1('ttm')\n",
    "data = extractor(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "Total background weight :  534759.9999999934\n",
      "Total signal weight :  534759.9999999983\n",
      "Number of background events :  534760.0\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "N = len(data['event'])\n",
    "n_bkg = N-sum([data['signal_label'][i] for i in range(len(data['signal_label']))])\n",
    "print(any(np.isnan(data['genWeight'])))\n",
    "data_norm = normalize(pd.DataFrame(data), 'mass_hyp', n_bkg)\n",
    "print(any(np.isnan(data_norm['genWeight'])))\n",
    "data_norm = normalize(data_norm, 'signal_label', n_bkg)\n",
    "print(any(np.isnan(data_norm['genWeight'])))\n",
    "print(\"Total background weight : \", sum(data_norm['genWeight'][i] for i in range(N) if data['signal_label'][i] == 0))\n",
    "print(\"Total signal weight : \", sum(data_norm['genWeight'][i] for i in range(N) if data['signal_label'][i] == 1))\n",
    "print(\"Number of background events : \", n_bkg)\n",
    "data_norm = normalize(data_norm, 'channel', n_bkg)\n",
    "print(any(np.isnan(data_norm['genWeight'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 7 8 9]\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "array = np.array([0,1,2,3,4,5,7,8,9])\n",
    "print(array)\n",
    "print(any(np.isnan(array)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['event', 'genWeight', 'deltaR_12', 'deltaR_13', 'deltaR_23', 'pt_123', 'mt_12', 'mt_13', 'mt_23', 'Mt_tot', 'n_tauh', 'mass_hyp', 'signal_label', 'channel', 'event_type']\n"
     ]
    }
   ],
   "source": [
    "data_processed, channel_indices = bucketize(data_norm, 'channel')\n",
    "print(list(data_processed.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vars = ['deltaR_13', 'deltaR_23', 'pt_123', 'mt_12', 'Mt_tot', 'channel', 'mass_hyp', 'signal_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Dnn_tau(input_vars)\n",
    "model.compile(loss='binary_crossentropy', \n",
    "                  optimizer='adam', \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=7)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"./saved_models/checkpoint\",\n",
    "    monitor = \"val_loss\",\n",
    "    save_best_only = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of events :  613875\n",
      "Train set : 37.55 %\n",
      "Validation set : 12.52 %\n",
      "Test set : 25.02 %\n",
      "Measurement set : 24.91 %\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "train, val, test, meas = split_dataset(data_processed)\n",
    "print(any(np.isnan(test['genWeight'])))\n",
    "x_train = train[input_vars]\n",
    "x_test = test[input_vars]\n",
    "x_val = val[input_vars]\n",
    "x_meas = meas[input_vars]\n",
    "\n",
    "label_train = x_train.pop('signal_label').astype(float)\n",
    "label_val = x_val.pop('signal_label').astype(float)\n",
    "label_test = x_test.pop('signal_label').astype(float)\n",
    "label_meas = x_meas.pop('signal_label').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000000\n",
      "577/577 [==============================] - 4s 7ms/step - loss: 1.4598 - accuracy: 0.4979 - val_loss: 0.9634 - val_accuracy: 0.3921\n",
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n",
      "Epoch 2/1000000\n",
      "577/577 [==============================] - 4s 6ms/step - loss: 0.6283 - accuracy: 0.3536 - val_loss: 0.7925 - val_accuracy: 0.3550\n",
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n",
      "Epoch 3/1000000\n",
      "577/577 [==============================] - 4s 6ms/step - loss: 0.5010 - accuracy: 0.4663 - val_loss: 0.7242 - val_accuracy: 0.5206\n",
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n",
      "Epoch 4/1000000\n",
      "577/577 [==============================] - 4s 6ms/step - loss: 0.4302 - accuracy: 0.5341 - val_loss: 0.6944 - val_accuracy: 0.5420\n",
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n",
      "Epoch 5/1000000\n",
      "577/577 [==============================] - 4s 6ms/step - loss: 0.4019 - accuracy: 0.5540 - val_loss: 0.6786 - val_accuracy: 0.5562\n",
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n",
      "Epoch 6/1000000\n",
      "577/577 [==============================] - 4s 6ms/step - loss: 0.3930 - accuracy: 0.5678 - val_loss: 0.6817 - val_accuracy: 0.5745\n",
      "Epoch 7/1000000\n",
      "577/577 [==============================] - 4s 7ms/step - loss: 0.3803 - accuracy: 0.5798 - val_loss: 0.6759 - val_accuracy: 0.5946\n",
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n",
      "Epoch 8/1000000\n",
      "577/577 [==============================] - 4s 6ms/step - loss: 0.3703 - accuracy: 0.5909 - val_loss: 0.6813 - val_accuracy: 0.5877\n",
      "Epoch 9/1000000\n",
      "577/577 [==============================] - 4s 7ms/step - loss: 0.3664 - accuracy: 0.5915 - val_loss: 0.6820 - val_accuracy: 0.5907\n",
      "Epoch 10/1000000\n",
      "577/577 [==============================] - 4s 7ms/step - loss: 0.3617 - accuracy: 0.5955 - val_loss: 0.6903 - val_accuracy: 0.5924\n",
      "Epoch 11/1000000\n",
      "577/577 [==============================] - 4s 7ms/step - loss: 0.3598 - accuracy: 0.6028 - val_loss: 0.6753 - val_accuracy: 0.6040\n",
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n",
      "Epoch 12/1000000\n",
      "577/577 [==============================] - 4s 7ms/step - loss: 0.3568 - accuracy: 0.6086 - val_loss: 0.6820 - val_accuracy: 0.6035\n",
      "Epoch 13/1000000\n",
      "577/577 [==============================] - 4s 7ms/step - loss: 0.3526 - accuracy: 0.6071 - val_loss: 0.6549 - val_accuracy: 0.6024\n",
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n",
      "Epoch 14/1000000\n",
      "577/577 [==============================] - 4s 7ms/step - loss: 0.3524 - accuracy: 0.6117 - val_loss: 0.6529 - val_accuracy: 0.6171\n",
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n",
      "Epoch 15/1000000\n",
      "577/577 [==============================] - 4s 7ms/step - loss: 0.3498 - accuracy: 0.6173 - val_loss: 0.6499 - val_accuracy: 0.6202\n",
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n",
      "Epoch 16/1000000\n",
      "577/577 [==============================] - 4s 7ms/step - loss: 0.3479 - accuracy: 0.6202 - val_loss: 0.6712 - val_accuracy: 0.6114\n",
      "Epoch 17/1000000\n",
      "577/577 [==============================] - 4s 7ms/step - loss: 0.3477 - accuracy: 0.6211 - val_loss: 0.6386 - val_accuracy: 0.6149\n",
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n",
      "Epoch 18/1000000\n",
      "577/577 [==============================] - 4s 6ms/step - loss: 0.3454 - accuracy: 0.6198 - val_loss: 0.6702 - val_accuracy: 0.6171\n",
      "Epoch 19/1000000\n",
      "577/577 [==============================] - 4s 7ms/step - loss: 0.3465 - accuracy: 0.6178 - val_loss: 0.6366 - val_accuracy: 0.6121\n",
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n",
      "Epoch 20/1000000\n",
      "577/577 [==============================] - 4s 6ms/step - loss: 0.3457 - accuracy: 0.6165 - val_loss: 0.6335 - val_accuracy: 0.6229\n",
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n",
      "Epoch 21/1000000\n",
      "577/577 [==============================] - 4s 6ms/step - loss: 0.3453 - accuracy: 0.6204 - val_loss: 0.6335 - val_accuracy: 0.6250\n",
      "Epoch 22/1000000\n",
      "577/577 [==============================] - 4s 7ms/step - loss: 0.3443 - accuracy: 0.6218 - val_loss: 0.6596 - val_accuracy: 0.6026\n",
      "Epoch 23/1000000\n",
      "577/577 [==============================] - 4s 7ms/step - loss: 0.3429 - accuracy: 0.6180 - val_loss: 0.6313 - val_accuracy: 0.6166\n",
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n",
      "Epoch 24/1000000\n",
      "577/577 [==============================] - 4s 6ms/step - loss: 0.3397 - accuracy: 0.6215 - val_loss: 0.6452 - val_accuracy: 0.6234\n",
      "Epoch 25/1000000\n",
      "577/577 [==============================] - 4s 7ms/step - loss: 0.3391 - accuracy: 0.6215 - val_loss: 0.6632 - val_accuracy: 0.6119\n",
      "Epoch 26/1000000\n",
      "577/577 [==============================] - 4s 7ms/step - loss: 0.3405 - accuracy: 0.6206 - val_loss: 0.6708 - val_accuracy: 0.6172\n",
      "Epoch 27/1000000\n",
      "577/577 [==============================] - 4s 7ms/step - loss: 0.3384 - accuracy: 0.6223 - val_loss: 0.6618 - val_accuracy: 0.6195\n",
      "Epoch 28/1000000\n",
      "577/577 [==============================] - 4s 6ms/step - loss: 0.3396 - accuracy: 0.6225 - val_loss: 0.6282 - val_accuracy: 0.6247\n",
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n",
      "Epoch 29/1000000\n",
      "577/577 [==============================] - 4s 6ms/step - loss: 0.3388 - accuracy: 0.6220 - val_loss: 0.6427 - val_accuracy: 0.6228\n",
      "Epoch 30/1000000\n",
      "577/577 [==============================] - 4s 7ms/step - loss: 0.3361 - accuracy: 0.6227 - val_loss: 0.6770 - val_accuracy: 0.6264\n",
      "Epoch 31/1000000\n",
      "577/577 [==============================] - 4s 6ms/step - loss: 0.3372 - accuracy: 0.6232 - val_loss: 0.6408 - val_accuracy: 0.6256\n",
      "Epoch 32/1000000\n",
      "577/577 [==============================] - 4s 7ms/step - loss: 0.3372 - accuracy: 0.6222 - val_loss: 0.6959 - val_accuracy: 0.6194\n",
      "Epoch 33/1000000\n",
      "577/577 [==============================] - 4s 7ms/step - loss: 0.3377 - accuracy: 0.6218 - val_loss: 0.6918 - val_accuracy: 0.6185\n",
      "Epoch 34/1000000\n",
      "577/577 [==============================] - 4s 7ms/step - loss: 0.3375 - accuracy: 0.6253 - val_loss: 0.6833 - val_accuracy: 0.6123\n",
      "Epoch 35/1000000\n",
      "577/577 [==============================] - 4s 7ms/step - loss: 0.3364 - accuracy: 0.6218 - val_loss: 0.7154 - val_accuracy: 0.6223\n",
      "Epoch 36/1000000\n",
      "577/577 [==============================] - 4s 7ms/step - loss: 0.3376 - accuracy: 0.6238 - val_loss: 0.6565 - val_accuracy: 0.6321\n",
      "Epoch 37/1000000\n",
      "577/577 [==============================] - 4s 7ms/step - loss: 0.3359 - accuracy: 0.6214 - val_loss: 0.7121 - val_accuracy: 0.6157\n",
      "Epoch 38/1000000\n",
      "577/577 [==============================] - 4s 7ms/step - loss: 0.3344 - accuracy: 0.6221 - val_loss: 0.6239 - val_accuracy: 0.6313\n",
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n",
      "Epoch 39/1000000\n",
      "577/577 [==============================] - 4s 6ms/step - loss: 0.3358 - accuracy: 0.6251 - val_loss: 0.6353 - val_accuracy: 0.6308\n",
      "Epoch 40/1000000\n",
      "577/577 [==============================] - 4s 7ms/step - loss: 0.3344 - accuracy: 0.6269 - val_loss: 0.6323 - val_accuracy: 0.6353\n",
      "Epoch 41/1000000\n",
      "577/577 [==============================] - 4s 7ms/step - loss: 0.3350 - accuracy: 0.6252 - val_loss: 0.7022 - val_accuracy: 0.6218\n",
      "Epoch 42/1000000\n",
      "577/577 [==============================] - 4s 7ms/step - loss: 0.3344 - accuracy: 0.6243 - val_loss: 0.6228 - val_accuracy: 0.6148\n",
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n",
      "Epoch 43/1000000\n",
      "577/577 [==============================] - 4s 7ms/step - loss: 0.3332 - accuracy: 0.6244 - val_loss: 0.6231 - val_accuracy: 0.6246\n",
      "Epoch 44/1000000\n",
      "577/577 [==============================] - 4s 7ms/step - loss: 0.3348 - accuracy: 0.6212 - val_loss: 0.6936 - val_accuracy: 0.6176\n",
      "Epoch 45/1000000\n",
      "577/577 [==============================] - 4s 6ms/step - loss: 0.3331 - accuracy: 0.6273 - val_loss: 0.6514 - val_accuracy: 0.6267\n",
      "Epoch 46/1000000\n",
      "577/577 [==============================] - 4s 6ms/step - loss: 0.3350 - accuracy: 0.6251 - val_loss: 0.6558 - val_accuracy: 0.6209\n",
      "Epoch 47/1000000\n",
      "577/577 [==============================] - 4s 7ms/step - loss: 0.3368 - accuracy: 0.6286 - val_loss: 0.6820 - val_accuracy: 0.6273\n",
      "Epoch 48/1000000\n",
      "577/577 [==============================] - 4s 7ms/step - loss: 0.3359 - accuracy: 0.6310 - val_loss: 0.6608 - val_accuracy: 0.6148\n",
      "Epoch 49/1000000\n",
      "577/577 [==============================] - 4s 7ms/step - loss: 0.3335 - accuracy: 0.6226 - val_loss: 0.6875 - val_accuracy: 0.6142\n",
      "Epoch 50/1000000\n",
      "577/577 [==============================] - 4s 7ms/step - loss: 0.3337 - accuracy: 0.6204 - val_loss: 0.6640 - val_accuracy: 0.6227\n",
      "Epoch 51/1000000\n",
      "577/577 [==============================] - 4s 7ms/step - loss: 0.3332 - accuracy: 0.6216 - val_loss: 0.6565 - val_accuracy: 0.6248\n",
      "Epoch 52/1000000\n",
      "577/577 [==============================] - 4s 7ms/step - loss: 0.3326 - accuracy: 0.6189 - val_loss: 0.6717 - val_accuracy: 0.6318\n",
      "Epoch 53/1000000\n",
      "577/577 [==============================] - 4s 7ms/step - loss: 0.3348 - accuracy: 0.6205 - val_loss: 0.6225 - val_accuracy: 0.6326\n",
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n",
      "Epoch 54/1000000\n",
      "577/577 [==============================] - 4s 6ms/step - loss: 0.3349 - accuracy: 0.6247 - val_loss: 0.6894 - val_accuracy: 0.6291\n",
      "Epoch 55/1000000\n",
      "577/577 [==============================] - 4s 7ms/step - loss: 0.3331 - accuracy: 0.6224 - val_loss: 0.6474 - val_accuracy: 0.6295\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(x_train, label_train, sample_weight=train['genWeight'], validation_data=(x_val, label_val), epochs=1000000, verbose=1, \n",
    "                    batch_size = 400, callbacks=[early_stopping, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 00:12:15.294051: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-24 00:12:16.161396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6673 MB memory:  -> device: 0, name: Quadro RTX 4000, pci bus id: 0000:17:00.0, compute capability: 7.5\n",
      "2023-04-24 00:12:16.162156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 6653 MB memory:  -> device: 1, name: Quadro RTX 4000, pci bus id: 0000:65:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.613, Test: 0.615\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"./saved_models/checkpoint\")\n",
    "\n",
    "_, train_acc = model.evaluate(x_train, label_train, verbose=0)\n",
    "_, test_acc = model.evaluate(x_test, label_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153615\n",
      "153615\n",
      "False\n",
      "True\n",
      "0    -0.043431\n",
      "1     0.040973\n",
      "4    -0.042646\n",
      "5     0.046229\n",
      "8     0.042637\n",
      "13    0.041822\n",
      "18    0.047479\n",
      "22   -0.045740\n",
      "24   -0.039032\n",
      "31   -0.045750\n",
      "Name: genWeight, dtype: float64\n",
      "0   -0.043431\n",
      "1    0.040973\n",
      "2         NaN\n",
      "3         NaN\n",
      "4   -0.042646\n",
      "5    0.046229\n",
      "6         NaN\n",
      "7         NaN\n",
      "8    0.042637\n",
      "9         NaN\n",
      "Name: genWeight, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(any(np.isnan(test['genWeight'])))\n",
    "\n",
    "output_test = pd.DataFrame({'scores': np.ravel(scores), 'genWeight': np.zeros(len(scores), dtype=np.float64)})\n",
    "output_test['genWeight'] = test['genWeight']\n",
    "\n",
    "print(any(np.isnan(output_test['genWeight'])))\n",
    "print(test['genWeight'][:10])\n",
    "print(output_test['genWeight'][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          scores  genWeight\n",
      "0   4.204079e-02  -0.043431\n",
      "1   6.471575e-01   0.040973\n",
      "2   4.618351e-01        NaN\n",
      "3   6.699303e-01        NaN\n",
      "4   4.887965e-02  -0.042646\n",
      "5   1.006886e-11   0.046229\n",
      "6   2.205556e-01        NaN\n",
      "7   6.919088e-01        NaN\n",
      "8   5.325562e-01   0.042637\n",
      "9   6.919088e-01        NaN\n",
      "10  6.474573e-01        NaN\n",
      "11  8.865919e-01        NaN\n",
      "12  3.826718e-02        NaN\n",
      "13  4.226846e-02   0.041822\n",
      "14  1.224800e-01        NaN\n",
      "15  6.979938e-01        NaN\n",
      "16  6.116828e-01        NaN\n",
      "17  6.919088e-01        NaN\n",
      "18  6.919088e-01   0.047479\n",
      "19  2.776740e-01        NaN\n"
     ]
    }
   ],
   "source": [
    "print(output_test[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(dataframe, keys, keys_label, bins_list, normalize = True, mode='n_tauh'):\n",
    "    colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "    if type(dataframe) == dict:\n",
    "        data_pd = pd.DataFrame(dataframe)\n",
    "    else:\n",
    "        data_pd = dataframe.copy()\n",
    "\n",
    "    sub_df = {}\n",
    "    if mode == 'n_tauh':\n",
    "        sub_df_keys =  [\"signal\", \"bkg_0\", \"bkg_1\", \"bkg_2\"]\n",
    "        event_type_labels = [\"signal\", r\"$background\\ 0\\times\\tau_h$\", r\"$background\\ 1\\times\\tau_h$\", r\"$background\\ 2\\times\\tau_h$\"]\n",
    "        signal = data_pd.loc[data_pd['signal_label']==1]\n",
    "        background = data_pd.loc[data_pd['signal_label']==0]\n",
    "        background_0 = background.loc[background['n_tauh']==0]\n",
    "        background_1 = background.loc[background['n_tauh']==1]\n",
    "        background_2 = background.loc[background['n_tauh']==2]\n",
    "        sub_df[sub_df_keys[0]] = signal\n",
    "        sub_df[sub_df_keys[1]] = background_0\n",
    "        sub_df[sub_df_keys[2]] = background_1\n",
    "        sub_df[sub_df_keys[3]] = background_2\n",
    "    if mode == 'simple':\n",
    "        sub_df_keys = ['Data']\n",
    "        event_type_labels = [None]\n",
    "        sub_df['Data'] = data_pd\n",
    "    else:\n",
    "        raise ValueError(f\"The mode {mode} is not valid\")\n",
    "    \n",
    "    figs = []\n",
    "\n",
    "    if type(keys) != list:\n",
    "        keys = [keys]\n",
    "        keys_label = [keys_label]\n",
    "        bins_list = [bins_list]\n",
    "    \n",
    "    for i,key in enumerate(keys):\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "        for j,event_type in enumerate(sub_df.keys()):\n",
    "            df = sub_df[event_type]\n",
    "            \n",
    "            if 'genWeight' not in list(df.keys()):\n",
    "                df['genWeight'] = np.ones_like(df[list(df.keys())[0]])\n",
    "\n",
    "            c,b = np.histogram(df[key], bins=bins_list[i], weights=df['genWeight'])\n",
    "            c2,_ = np.histogram(df[key], bins=bins_list[i], weights=df['genWeight']**2)\n",
    "            if normalize:\n",
    "                norm = np.linalg.norm(c)\n",
    "                c /= norm\n",
    "                c2 /= norm**2\n",
    "            \n",
    "            if event_type_labels[j] != None:\n",
    "                ax.stairs(c, b, label=event_type_labels[j], linewidth=2)\n",
    "            else:\n",
    "                ax.stairs(c, b, linewidth=2)\n",
    "            # ax.errorbar((b[1:]+b[:-1])/2, c, yerr = np.sqrt(c2), marker = '.',drawstyle = 'steps-mid', color=colors[j])\n",
    "            ax.errorbar((b[1:]+b[:-1])/2, c, yerr = np.sqrt(c2),fmt='.', color='k', linewidth=1)\n",
    "            ax.set_xlabel(keys_label[i])\n",
    "            if mode != 'simple':\n",
    "                ax.legend()\n",
    "            ax.grid(True)\n",
    "        figs.append(fig)\n",
    "    return figs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins_list = np.linspace(0,1,20)\n",
    "figs = plot_hist(output_test, 'scores', 'DNN score', bins_list, normalize = True, mode='simple')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
