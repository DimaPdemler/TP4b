{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import uproot\n",
    "import awkward as ak\n",
    "import vector\n",
    "import numba as nb\n",
    "import os\n",
    "import fnmatch\n",
    "from dnn_tau import Dnn_tau\n",
    "from kinematic import *\n",
    "from utils import isolate_int, normalize\n",
    "import pandas as pd\n",
    "from numbers import Number\n",
    "from utils import normalize, split_dataset, bucketize, plot_hist\n",
    "from data_extractor import Data_extractor_v1\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/data/hnl/prompt_tau/anatuple/nanoV10/TEST9/ttm/anatuple/\"\n",
    "extractor = Data_extractor_v1('ttm')\n",
    "data = extractor(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total background weight :  801843.0000000028\n",
      "Total signal weight :  801843.0000000059\n",
      "Number of background events :  801843.0\n",
      "Total number of events :  891987\n"
     ]
    }
   ],
   "source": [
    "N = len(data['event'])\n",
    "n_bkg = N-sum([data['signal_label'][i] for i in range(len(data['signal_label']))])\n",
    "data_norm = normalize(pd.DataFrame(data), 'mass_hyp', n_bkg)\n",
    "data_norm = normalize(data_norm, 'signal_label', n_bkg)\n",
    "print(\"Total background weight : \", sum(data_norm['genWeight'][i] for i in range(N) if data['signal_label'][i] == 0))\n",
    "print(\"Total signal weight : \", sum(data_norm['genWeight'][i] for i in range(N) if data['signal_label'][i] == 1))\n",
    "print(\"Number of background events : \", n_bkg)\n",
    "print(\"Total number of events : \", N)\n",
    "data_norm = normalize(data_norm, 'channel', n_bkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['event', 'genWeight', 'deltaR_12', 'deltaR_13', 'deltaR_23', 'pt_123', 'mt_12', 'mt_13', 'mt_23', 'Mt_tot', 'n_tauh', 'mass_hyp', 'signal_label', 'channel', 'event_type']\n"
     ]
    }
   ],
   "source": [
    "data_processed, channel_indices = bucketize(data_norm, 'channel')\n",
    "print(list(data_processed.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vars = ['deltaR_13', 'deltaR_23', 'pt_123', 'mt_12', 'Mt_tot', 'channel', 'mass_hyp', 'signal_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Dnn_tau(input_vars)\n",
    "model.compile(loss='binary_crossentropy', \n",
    "                  optimizer='adam', \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=7)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"./saved_models/checkpoint\",\n",
    "    monitor = \"val_loss\",\n",
    "    save_best_only = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of events :  891987\n",
      "Train set : 37.58 %\n",
      "Validation set : 12.53 %\n",
      "Test set : 25.00 %\n",
      "Measurement set : 24.90 %\n"
     ]
    }
   ],
   "source": [
    "train, val, test, meas = split_dataset(data_processed)\n",
    "x_train = train[input_vars]\n",
    "x_test = test[input_vars]\n",
    "x_val = val[input_vars]\n",
    "x_meas = meas[input_vars]\n",
    "\n",
    "label_train = x_train.pop('signal_label').astype(float)\n",
    "label_val = x_val.pop('signal_label').astype(float)\n",
    "label_test = x_test.pop('signal_label').astype(float)\n",
    "label_meas = x_meas.pop('signal_label').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000000\n",
      "838/838 [==============================] - 6s 6ms/step - loss: 0.7975 - accuracy: 0.4850 - val_loss: 0.7045 - val_accuracy: 0.4961\n",
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/1000000\n",
      "838/838 [==============================] - 5s 6ms/step - loss: 0.5074 - accuracy: 0.5292 - val_loss: 0.6728 - val_accuracy: 0.5651\n",
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/1000000\n",
      "838/838 [==============================] - 5s 6ms/step - loss: 0.4725 - accuracy: 0.5603 - val_loss: 0.6641 - val_accuracy: 0.5603\n",
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/1000000\n",
      "838/838 [==============================] - 5s 6ms/step - loss: 0.4523 - accuracy: 0.5663 - val_loss: 0.6716 - val_accuracy: 0.5712\n",
      "Epoch 5/1000000\n",
      "838/838 [==============================] - 5s 6ms/step - loss: 0.4386 - accuracy: 0.5696 - val_loss: 0.6609 - val_accuracy: 0.5718\n",
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/1000000\n",
      "838/838 [==============================] - 5s 6ms/step - loss: 0.4270 - accuracy: 0.5795 - val_loss: 0.6323 - val_accuracy: 0.5886\n",
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/1000000\n",
      "838/838 [==============================] - 5s 6ms/step - loss: 0.4099 - accuracy: 0.5971 - val_loss: 0.6496 - val_accuracy: 0.5909\n",
      "Epoch 8/1000000\n",
      "838/838 [==============================] - 5s 6ms/step - loss: 0.4039 - accuracy: 0.6052 - val_loss: 0.6361 - val_accuracy: 0.6068\n",
      "Epoch 9/1000000\n",
      "838/838 [==============================] - 5s 6ms/step - loss: 0.3959 - accuracy: 0.6135 - val_loss: 0.6289 - val_accuracy: 0.6156\n",
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/1000000\n",
      "838/838 [==============================] - 5s 6ms/step - loss: 0.3861 - accuracy: 0.6163 - val_loss: 0.6177 - val_accuracy: 0.6220\n",
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/1000000\n",
      "838/838 [==============================] - 5s 6ms/step - loss: 0.3813 - accuracy: 0.6334 - val_loss: 0.6071 - val_accuracy: 0.6527\n",
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/1000000\n",
      "838/838 [==============================] - 5s 6ms/step - loss: 0.3789 - accuracy: 0.6437 - val_loss: 0.6283 - val_accuracy: 0.6410\n",
      "Epoch 13/1000000\n",
      "838/838 [==============================] - 5s 6ms/step - loss: 0.3796 - accuracy: 0.6447 - val_loss: 0.6123 - val_accuracy: 0.6467\n",
      "Epoch 14/1000000\n",
      "838/838 [==============================] - 5s 6ms/step - loss: 0.3772 - accuracy: 0.6413 - val_loss: 0.5947 - val_accuracy: 0.6531\n",
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/1000000\n",
      "838/838 [==============================] - 5s 6ms/step - loss: 0.3769 - accuracy: 0.6517 - val_loss: 0.5957 - val_accuracy: 0.6532\n",
      "Epoch 16/1000000\n",
      "838/838 [==============================] - 5s 6ms/step - loss: 0.3718 - accuracy: 0.6536 - val_loss: 0.6149 - val_accuracy: 0.6619\n",
      "Epoch 17/1000000\n",
      "838/838 [==============================] - 5s 6ms/step - loss: 0.3735 - accuracy: 0.6594 - val_loss: 0.5775 - val_accuracy: 0.6758\n",
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/1000000\n",
      "838/838 [==============================] - 5s 6ms/step - loss: 0.3731 - accuracy: 0.6585 - val_loss: 0.6324 - val_accuracy: 0.6534\n",
      "Epoch 19/1000000\n",
      "838/838 [==============================] - 5s 6ms/step - loss: 0.3720 - accuracy: 0.6688 - val_loss: 0.6278 - val_accuracy: 0.6526\n",
      "Epoch 20/1000000\n",
      "838/838 [==============================] - 5s 6ms/step - loss: 0.3720 - accuracy: 0.6679 - val_loss: 0.5892 - val_accuracy: 0.6645\n",
      "Epoch 21/1000000\n",
      "838/838 [==============================] - 5s 6ms/step - loss: 0.3691 - accuracy: 0.6686 - val_loss: 0.6064 - val_accuracy: 0.6586\n",
      "Epoch 22/1000000\n",
      "838/838 [==============================] - 5s 6ms/step - loss: 0.3720 - accuracy: 0.6654 - val_loss: 0.6081 - val_accuracy: 0.6540\n",
      "Epoch 23/1000000\n",
      "838/838 [==============================] - 5s 6ms/step - loss: 0.3695 - accuracy: 0.6610 - val_loss: 0.6185 - val_accuracy: 0.6527\n",
      "Epoch 24/1000000\n",
      "838/838 [==============================] - 5s 6ms/step - loss: 0.3654 - accuracy: 0.6663 - val_loss: 0.6102 - val_accuracy: 0.6663\n",
      "Epoch 25/1000000\n",
      "838/838 [==============================] - 5s 6ms/step - loss: 0.3658 - accuracy: 0.6666 - val_loss: 0.5976 - val_accuracy: 0.6744\n",
      "Epoch 26/1000000\n",
      "838/838 [==============================] - 5s 6ms/step - loss: 0.3656 - accuracy: 0.6703 - val_loss: 0.6177 - val_accuracy: 0.6587\n",
      "Epoch 27/1000000\n",
      "838/838 [==============================] - 5s 6ms/step - loss: 0.3657 - accuracy: 0.6682 - val_loss: 0.5702 - val_accuracy: 0.6800\n",
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/1000000\n",
      "838/838 [==============================] - 5s 6ms/step - loss: 0.3649 - accuracy: 0.6683 - val_loss: 0.5611 - val_accuracy: 0.6754\n",
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/1000000\n",
      "838/838 [==============================] - 5s 6ms/step - loss: 0.3655 - accuracy: 0.6637 - val_loss: 0.5621 - val_accuracy: 0.6763\n",
      "Epoch 30/1000000\n",
      "838/838 [==============================] - 5s 6ms/step - loss: 0.3637 - accuracy: 0.6656 - val_loss: 0.6125 - val_accuracy: 0.6597\n",
      "Epoch 31/1000000\n",
      "838/838 [==============================] - 5s 6ms/step - loss: 0.3641 - accuracy: 0.6668 - val_loss: 0.5744 - val_accuracy: 0.6780\n",
      "Epoch 32/1000000\n",
      "838/838 [==============================] - 5s 6ms/step - loss: 0.3636 - accuracy: 0.6796 - val_loss: 0.6077 - val_accuracy: 0.6759\n",
      "Epoch 33/1000000\n",
      "838/838 [==============================] - 5s 6ms/step - loss: 0.3644 - accuracy: 0.6686 - val_loss: 0.6098 - val_accuracy: 0.6668\n",
      "Epoch 34/1000000\n",
      "838/838 [==============================] - 5s 6ms/step - loss: 0.3633 - accuracy: 0.6709 - val_loss: 0.6123 - val_accuracy: 0.6587\n",
      "Epoch 35/1000000\n",
      "838/838 [==============================] - 5s 6ms/step - loss: 0.3624 - accuracy: 0.6729 - val_loss: 0.5872 - val_accuracy: 0.6849\n",
      "Epoch 36/1000000\n",
      "838/838 [==============================] - 5s 6ms/step - loss: 0.3635 - accuracy: 0.6774 - val_loss: 0.6726 - val_accuracy: 0.6561\n",
      "Epoch 37/1000000\n",
      "838/838 [==============================] - 5s 6ms/step - loss: 0.3647 - accuracy: 0.6688 - val_loss: 0.5823 - val_accuracy: 0.6621\n",
      "Epoch 38/1000000\n",
      "838/838 [==============================] - 5s 6ms/step - loss: 0.3652 - accuracy: 0.6648 - val_loss: 0.6292 - val_accuracy: 0.6449\n",
      "Epoch 39/1000000\n",
      "838/838 [==============================] - 5s 6ms/step - loss: 0.3621 - accuracy: 0.6522 - val_loss: 0.6015 - val_accuracy: 0.6508\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, label_train, sample_weight=train['genWeight'], validation_data=(x_val, label_val), epochs=1000000, verbose=1, \n",
    "                    batch_size = 400, callbacks=[early_stopping, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models/TEST9_with_initial_vars_for_score_hist/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models/TEST9_with_initial_vars_for_score_hist/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('./saved_models/TEST9_with_initial_vars_for_score_hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 15:33:06.319284: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-24 15:33:07.248401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 409 MB memory:  -> device: 0, name: Quadro RTX 4000, pci bus id: 0000:17:00.0, compute capability: 7.5\n",
      "2023-04-24 15:33:07.249106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 6398 MB memory:  -> device: 1, name: Quadro RTX 4000, pci bus id: 0000:65:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.645, Test accuracy: 0.643\n",
      "Train loss: 0.532, Test loss: 0.533\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"./saved_models/TEST9_with_initial_vars_for_score_hist\")\n",
    "\n",
    "train_loss, train_acc = model.evaluate(x_train, label_train, verbose=0)\n",
    "test_loss, test_acc = model.evaluate(x_test, label_test, verbose=0)\n",
    "print('Train accuracy: %.3f, Test accuracy: %.3f' % (train_acc, test_acc))\n",
    "print('Train loss: %.3f, Test loss: %.3f' % (train_loss, test_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.predict(x_test)\n",
    "output_test = pd.DataFrame({'scores':np.ravel(scores), 'genWeight':test['genWeight'], 'signal_label':label_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams.update({\"font.size\": 16, \"font.family\": \"serif\"})\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores\n",
      "0\n",
      "['scores', 'genWeight', 'signal_label']\n",
      "scores\n",
      "0\n",
      "['scores', 'genWeight', 'signal_label']\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins_list = np.linspace(0,1,19)\n",
    "figs, counts = plot_hist(output_test, 'scores', 'DNN score', bins_list, normalize = True, mode='simple_signal_label', return_counts=True)\n",
    "figs[0].savefig(\"Images/TEST9_ttm_score_hist.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missclassified signal : 5.47%\n",
      "Correctly classified signal : 94.53%\n",
      "Missclassified background : 28.85%\n",
      "Correctly classified background : 71.15%\n"
     ]
    }
   ],
   "source": [
    "bins_center = (bins_list[1:]+bins_list[:-1])/2\n",
    "classed_bkg = (bins_center < 0.5)\n",
    "values_s = counts[0]['signal']['counts']\n",
    "values_b = counts[0]['bkg']['counts']\n",
    "ratio_miss_s = values_s[classed_bkg].sum()/values_s.sum()\n",
    "ratio_well_s = values_s[(1-classed_bkg).astype(bool)].sum()/values_s.sum()\n",
    "ratio_miss_b = values_b[(1-classed_bkg).astype(bool)].sum()/values_b.sum()\n",
    "ratio_well_b = values_b[classed_bkg].sum()/values_b.sum()\n",
    "print(\"Missclassified signal : {:.2f}%\".format(ratio_miss_s*100))\n",
    "print(\"Correctly classified signal : {:.2f}%\".format(ratio_well_s*100))\n",
    "print(\"Missclassified background : {:.2f}%\".format(ratio_miss_b*100))\n",
    "print(\"Correctly classified background : {:.2f}%\".format(ratio_well_b*100))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with selection of important variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from train_model import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle('extracted_data/TEST9_global_v4_train')\n",
    "val = pd.read_pickle('extracted_data/TEST9_global_v4_val')\n",
    "meas = pd.read_pickle('extracted_data/TEST9_global_v4_meas')\n",
    "test = pd.read_pickle('extracted_data/TEST9_global_v4_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"saved_results/selected_vars_threshold_100\"\n",
    "with open(filename, 'rb') as file:\n",
    "    features = pickle.load(file)\n",
    "\n",
    "features.append('channel')\n",
    "selected_vars = deepcopy(features)\n",
    "selected_vars.append('signal_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mt_1MET', 'HNL_CM_mass_with_MET_1', 'mt_12', 'mass_12', 'pt_2', 'mass_123', 'HNL_CM_mass_2', 'mt_1(3MET)', 'mt_23', 'HNL_CM_mass_1', 'HNL_CM_mass_with_MET_2', 'mt_3MET', 'pt_MET', 'mass_23', 'mt_2(1MET)', 'mt_1(2MET)', 'mt_MET(23)', 'Mt_tot', 'mt_MET(13)', 'mass_hyp', 'pt_123', 'pt_1', 'mt_2MET', 'mt_3(2MET)', 'mt_1(23)', 'mt_2(13)', 'mass_13', 'mt_13', 'channel', 'signal_label']\n"
     ]
    }
   ],
   "source": [
    "print(selected_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('saved_results/features&label_sel1', 'wb') as file:\n",
    "    pickle.dump(selected_vars, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 21:52:34.491366: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-22 21:52:35.458404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6673 MB memory:  -> device: 0, name: Quadro RTX 4000, pci bus id: 0000:17:00.0, compute capability: 7.5\n",
      "2023-05-22 21:52:35.459182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 6653 MB memory:  -> device: 1, name: Quadro RTX 4000, pci bus id: 0000:65:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100000\n",
      "1727/1727 [==============================] - 11s 6ms/step - loss: 1.7617 - accuracy: 0.5651 - weighted_accuracy: 0.8723 - val_loss: 1.1634 - val_accuracy: 0.5989 - val_weighted_accuracy: 0.8944\n",
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n",
      "Epoch 2/100000\n",
      "   1/1727 [..............................] - ETA: 6s - loss: 0.6631 - accuracy: 0.5657 - weighted_accuracy: 0.9051"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 21:52:47.893559: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1727/1727 [==============================] - 10s 6ms/step - loss: 0.4270 - accuracy: 0.6025 - weighted_accuracy: 0.8983 - val_loss: 0.2525 - val_accuracy: 0.5604 - val_weighted_accuracy: 0.9053\n",
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n",
      "Epoch 3/100000\n",
      "1727/1727 [==============================] - 10s 6ms/step - loss: 0.2330 - accuracy: 0.6112 - weighted_accuracy: 0.9152 - val_loss: 0.2097 - val_accuracy: 0.6542 - val_weighted_accuracy: 0.9198\n",
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n",
      "Epoch 4/100000\n",
      "1727/1727 [==============================] - 10s 6ms/step - loss: 0.2081 - accuracy: 0.6260 - weighted_accuracy: 0.9238 - val_loss: 0.1983 - val_accuracy: 0.6197 - val_weighted_accuracy: 0.9276\n",
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n",
      "Epoch 5/100000\n",
      "1727/1727 [==============================] - 10s 6ms/step - loss: 0.2010 - accuracy: 0.6261 - weighted_accuracy: 0.9260 - val_loss: 0.1933 - val_accuracy: 0.6103 - val_weighted_accuracy: 0.9271\n",
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n",
      "Epoch 6/100000\n",
      "1727/1727 [==============================] - 10s 6ms/step - loss: 0.1953 - accuracy: 0.6322 - weighted_accuracy: 0.9276 - val_loss: 0.1989 - val_accuracy: 0.6573 - val_weighted_accuracy: 0.9266\n",
      "Epoch 7/100000\n",
      "1727/1727 [==============================] - 10s 6ms/step - loss: 0.1956 - accuracy: 0.6329 - weighted_accuracy: 0.9277 - val_loss: 0.2030 - val_accuracy: 0.6346 - val_weighted_accuracy: 0.9235\n",
      "Epoch 8/100000\n",
      "1727/1727 [==============================] - 10s 6ms/step - loss: 0.1932 - accuracy: 0.6322 - weighted_accuracy: 0.9282 - val_loss: 0.1933 - val_accuracy: 0.6380 - val_weighted_accuracy: 0.9279\n",
      "Epoch 9/100000\n",
      "1727/1727 [==============================] - 10s 6ms/step - loss: 0.1899 - accuracy: 0.6387 - weighted_accuracy: 0.9303 - val_loss: 0.1833 - val_accuracy: 0.6485 - val_weighted_accuracy: 0.9312\n",
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n",
      "Epoch 10/100000\n",
      "1727/1727 [==============================] - 10s 6ms/step - loss: 0.1894 - accuracy: 0.6387 - weighted_accuracy: 0.9300 - val_loss: 0.1859 - val_accuracy: 0.6309 - val_weighted_accuracy: 0.9305\n",
      "Epoch 11/100000\n",
      "1727/1727 [==============================] - 10s 6ms/step - loss: 0.1870 - accuracy: 0.6462 - weighted_accuracy: 0.9310 - val_loss: 0.1857 - val_accuracy: 0.6269 - val_weighted_accuracy: 0.9304\n",
      "Epoch 12/100000\n",
      "1727/1727 [==============================] - 10s 6ms/step - loss: 0.1890 - accuracy: 0.6432 - weighted_accuracy: 0.9311 - val_loss: 0.1848 - val_accuracy: 0.6336 - val_weighted_accuracy: 0.9298\n",
      "Epoch 13/100000\n",
      "1727/1727 [==============================] - 10s 6ms/step - loss: 0.1869 - accuracy: 0.6384 - weighted_accuracy: 0.9306 - val_loss: 0.1948 - val_accuracy: 0.6882 - val_weighted_accuracy: 0.9277\n",
      "Epoch 14/100000\n",
      "1727/1727 [==============================] - 10s 6ms/step - loss: 0.1876 - accuracy: 0.6473 - weighted_accuracy: 0.9305 - val_loss: 0.1915 - val_accuracy: 0.6376 - val_weighted_accuracy: 0.9271\n",
      "Epoch 15/100000\n",
      "1727/1727 [==============================] - 10s 6ms/step - loss: 0.1899 - accuracy: 0.6346 - weighted_accuracy: 0.9289 - val_loss: 0.1861 - val_accuracy: 0.6337 - val_weighted_accuracy: 0.9301\n",
      "Epoch 16/100000\n",
      "1727/1727 [==============================] - 10s 6ms/step - loss: 0.1871 - accuracy: 0.6369 - weighted_accuracy: 0.9304 - val_loss: 0.1817 - val_accuracy: 0.6440 - val_weighted_accuracy: 0.9327\n",
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n",
      "Epoch 17/100000\n",
      "1727/1727 [==============================] - 10s 6ms/step - loss: 0.1853 - accuracy: 0.6424 - weighted_accuracy: 0.9322 - val_loss: 0.1811 - val_accuracy: 0.6654 - val_weighted_accuracy: 0.9344\n",
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n",
      "Epoch 18/100000\n",
      "1727/1727 [==============================] - 10s 6ms/step - loss: 0.1856 - accuracy: 0.6460 - weighted_accuracy: 0.9306 - val_loss: 0.1896 - val_accuracy: 0.6389 - val_weighted_accuracy: 0.9292\n",
      "Epoch 19/100000\n",
      "1727/1727 [==============================] - 10s 6ms/step - loss: 0.1827 - accuracy: 0.6527 - weighted_accuracy: 0.9333 - val_loss: 0.1815 - val_accuracy: 0.6514 - val_weighted_accuracy: 0.9294\n",
      "Epoch 20/100000\n",
      "1727/1727 [==============================] - 10s 6ms/step - loss: 0.1886 - accuracy: 0.6354 - weighted_accuracy: 0.9299 - val_loss: 0.1794 - val_accuracy: 0.6553 - val_weighted_accuracy: 0.9331\n",
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n",
      "Epoch 21/100000\n",
      "1727/1727 [==============================] - 10s 6ms/step - loss: 0.1874 - accuracy: 0.6367 - weighted_accuracy: 0.9300 - val_loss: 0.1872 - val_accuracy: 0.6626 - val_weighted_accuracy: 0.9289\n",
      "Epoch 22/100000\n",
      "1727/1727 [==============================] - 10s 6ms/step - loss: 0.1863 - accuracy: 0.6402 - weighted_accuracy: 0.9306 - val_loss: 0.1815 - val_accuracy: 0.6539 - val_weighted_accuracy: 0.9313\n",
      "Epoch 23/100000\n",
      "1727/1727 [==============================] - 10s 6ms/step - loss: 0.1846 - accuracy: 0.6415 - weighted_accuracy: 0.9320 - val_loss: 0.1829 - val_accuracy: 0.6218 - val_weighted_accuracy: 0.9308\n",
      "Epoch 24/100000\n",
      "1727/1727 [==============================] - 10s 6ms/step - loss: 0.1817 - accuracy: 0.6442 - weighted_accuracy: 0.9341 - val_loss: 0.1853 - val_accuracy: 0.6262 - val_weighted_accuracy: 0.9283\n",
      "Epoch 25/100000\n",
      "1727/1727 [==============================] - 10s 6ms/step - loss: 0.1805 - accuracy: 0.6449 - weighted_accuracy: 0.9351 - val_loss: 0.1874 - val_accuracy: 0.6709 - val_weighted_accuracy: 0.9328\n",
      "Epoch 26/100000\n",
      "1727/1727 [==============================] - 10s 6ms/step - loss: 0.1789 - accuracy: 0.6468 - weighted_accuracy: 0.9351 - val_loss: 0.1847 - val_accuracy: 0.6264 - val_weighted_accuracy: 0.9292\n",
      "Epoch 27/100000\n",
      "1727/1727 [==============================] - 10s 6ms/step - loss: 0.1811 - accuracy: 0.6417 - weighted_accuracy: 0.9329 - val_loss: 0.1825 - val_accuracy: 0.6605 - val_weighted_accuracy: 0.9348\n",
      "Epoch 28/100000\n",
      "1727/1727 [==============================] - 10s 6ms/step - loss: 0.1786 - accuracy: 0.6515 - weighted_accuracy: 0.9343 - val_loss: 0.1793 - val_accuracy: 0.6474 - val_weighted_accuracy: 0.9338\n",
      "INFO:tensorflow:Assets written to: ./saved_models/checkpoint/assets\n",
      "Epoch 29/100000\n",
      "1727/1727 [==============================] - 10s 6ms/step - loss: 0.1799 - accuracy: 0.6464 - weighted_accuracy: 0.9334 - val_loss: 0.1810 - val_accuracy: 0.6167 - val_weighted_accuracy: 0.9286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, dense_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/TEST9_sel1_depth_1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/TEST9_sel1_depth_1/assets\n"
     ]
    }
   ],
   "source": [
    "depths = [1]\n",
    "\n",
    "for depth in depths:\n",
    "    train_model(depth, train, val, selected_vars, 'saved_models/TEST9_sel1_depth_{}'.format(depth), 'saved_history/TEST9_sel1_depth_{}'.format(depth))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
